---
title: "**DISTRIBUCIONES DE PROBABILIDAD**"
author: 
date: '`r Sys.Date()`'
output:
  pdf_document:
    toc: true
    toc_depth: 3
  html_document:
    df_print: paged
header-includes:
  - \usepackage{titletoc}
  - \usepackage{xlop}
  - \titlecontents{section}[0em]{\bfseries}{}{}{\titlerule*[1pc]{.}\contentspage}
  - \renewcommand{\contentsname}{ÍNDICE}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

## **DISTRIBUCIONES DISCRETAS**

\vspace{12pt}
### **DISTRIBUCIÓN BINOMIAL**

Mide el número de éxitos en una secuencia de $n$ ensayos de Bernoulli independientes entre sí con una probabilidad $p$ de éxito entre los ensayos.

\[ P(X = x) = \binom{n}{x} p^x (1 - p)^{n - x} \]

Es la probabilidad de tener $x$ éxitos en $n$ ensayos.

**EJEMPLO**

La probabilidad de que un jugador de baloncesto enceste un triple es del 30 %, es decir, $p = 0.3$. Suponemos que lanza $5$ veces, $n = 5$.

a) Si quieremos calcular la probabilidad de que enceste tres tiros $(P(X = 3))$:

    ```{r}
    dbinom(3, size = 5, prob = 0.3)
    ```

b) Si queremos calcular todas las probabilidades de golpe en forma de tabla:

    ```{r}
    RBinom <- data.frame(Pr = dbinom(0:5, size = 5, prob = 0.3))
    rownames(RBinom) <- 0:5
    RBinom
    ```

c) La probabilidad de encestar más de $3$ triples $(P(X \geq 3))$:

    ```{r}
    pbinom(3, size = 5, prob = 0.3, lower.tail = FALSE)
    ```

d) Si queremos saber todas las probabilidades acumuladas (más de $0$, más de $1$, ...), calculamos la cola derecha $(P(X > x))$:

    ```{r}
    pbinom(0:5, size = 5, prob = 0.3, lower.tail = FALSE)
    ```

e) Si queremos calcular las colas izquierdas $(P(X \leq x))$, esto es, la probabilidad de encestar menos de $1$, menos de $2$, ...:

    ```{r}
    pbinom(0:5, size = 5, prob = 0.3, lower.tail = TRUE)
    ```

f) La probabilidad de encestar menos de dos tiros $(P(X \leq 1))$:

    ```{r}
    pbinom(1, size = 5, prob = 0.3, lower.tail = TRUE)
    ```

g) Para representar gráficamente la función de probabilidad:

    ```{r}
    x <- 0:5
    Binom_plot <- dbinom(x, size = 5, prob = 0.3)
    plot(x, Binom_plot, main = "Distribución binomial (n = 5, p = 0.3)",
         xlab = "Número de sucesos", ylab = "Masa de probabilidad",
         type = "h")
    ```

h) Para representar gráficamente la función de probabilidad acumulada:

    ```{r}
    x <- 0:5
    Acum <- pbinom(x, size = 5, prob = 0.3)
    plot(x, Acum, main = "Distribución binomial (n = 5, p = 0.3)",
         xlab = "Número de sucesos", ylab = "Probabilidad acumulada",
         type = "s")
    ```

### **DISTRIBUCIÓN GEOMÉTRICA**

Describe la probabilidad del número de ensayos de Bernoulli necesarios para obtener un éxito.

\[P(X = x) = (1 - p)^{x - 1} p \]

\[P(X \leq x) = F(x) = 1 - (1 - p)^x \]

En este caso, $x$ es el número de intento en el que el jugador tendrá éxito (encestará el triple) y $p$ es la probabilidad de encestar.

**EJEMPLO**

Definimos una variable aleatoria $X$, que será el número del intento en el que el jugador encesta el primer triple, es decir, el número de ensayos necesarios hasta encestar.

a) Si queremos saber la probabilidad de que el primer triple que enceste sea en el sexto intento con una probablidad de encestar de $p = 0.3$ $(P(X \leq 6) = F(6))$:

    ```{r}
    pgeom(5, prob = 0.3, lower.tail = TRUE)
    ```

    Donde el primer número $(5)$ es el **número de fallos** antes del primer acierto, esto es $x - 1$. Estamos calculando la **cola izquierda** $(P(X \leq x))$.

b) Para hacer la representación gráfica tomando $20$ como el número máximo de intentos antes de acertar, definimos primero el vector $x$ que contiene el número de intentos, y el vector $y$, que contiene la probabilidad de acertar el primer triple en el i-ésimo tiro:

    ```{r}
    x <- 0:20
    y <- dgeom(x, prob = 0.3)
    plot(x, y, main = "Distribución geométrica (p = 0.3)",
         xlab = "Número de errores hasta acertar", 
         ylab = "Masa de probabilidad", type = "h")
    ```

### **DISTRIBUCIÓN HIPERGEOMÉTRICA**

Se da cuando las observaciones no son independientes. Supongamos que tenemos una muestra de $N$ bolas, de las cuales $N_1$ son verdes y $N_2$ son rojas, de modo que $N_1 + N_2 = N$. Si extraemos $n$ bolas (sin retorno), la variable $X$ será el número de bolas verdes obtenidas.

\[ P(X = x) = \frac{\binom{N_1}{x} \binom{N_2}{n - x}}{\binom{N}{n}} \]

**EJEMPLO**

Un estudiante de oposiciones ha preparado doce de los dieciocho temas de los que consta el examen. La prueba consiste en tres temas elegidos de manera aleatoria. ¿Qué probabilidad tiene el estudiante de conocer los tres temas? Sabemos que $N_1 = 12$, $N_2 = 6$ y $N = 18$. Además, la extracción es $n = 3$.

```{r}
RHiper <- data.frame(Pr = dhyper(0:3, m = 12, n = 6, k = 3))
rownames(RHiper) <- 0:3
RHiper
```

La probabilidad de que los tres temas que ha estudiado entren en el examen es del $26.9 \; \%$. La probabilidad más alta es $P(X = 2) = 0.485$, es decir, que haya estudiado dos de los tres temas que saldrán.

a) Si queremos saber la probabilidad de que sepa como mínimo dos temas $(P(X \geq 2))$, necesitamos la probabilidad acumulada de la cola derecha. $R$ calcula $P(X > x)$, así que tendremos que calcular la función de distribución con $x = 1$ porque $P(X > 1) = P(X \geq 2)$:

    ```{r}
    phyper(1, m = 12, n = 6, k = 3, lower.tail = FALSE)
    ```

    Esto significa que tiene una probabilidad del $75 \; \%$ de que conozca dos o tres temas en el examen.

### **DISTRIBUCIÓN DE POISON**

Como las anteriores, también se deriva de la distribución binomial.

**EJEMPLO**

Tomamos una variable $X$, definida como el tiempo de espera del autobús en minutos, y que tiene como único parámetro $\lambda$, que representa tanto la media, como la varianza de la variable aleatoria.

Supongamos que el tiempo de espera es de $3$ minutos, o sea, $\lambda = 3$.

a) Para saber la probabilidad de que el autobús tarde $5$ minutos:

    \[ P(X = 5) = \frac{\lambda^k}{k!}e^{-\lambda} = \frac{3^5}{5!}e^{-3} = 0.1008 \]

b) Si queremos saber la probabilidad de los once primeros valores (desde $P(X = 0)$ hasta $P(X = 10)$):

    ```{r}
    RPoiss <- data.frame(Pr = dpois(0:10, lambda = 3))
    rownames(RPoiss) <- 0:10
    RPoiss
    ```

Al igual que en las distribuciones anteriores, se pueden calcular las probabilidades acumuladas, gráficos y simulaciones muestrales.

\newpage

## **DISTRIBUCIONES CONTINUAS**

\vspace{12pt}
### **DISTRIBUCIÓN UNIFORME**

El dominio de esta distribución está definido por los valores máximo y mínimo $a$ y $b$. Su función de densidad viene dada por:

\[ f(x) = \left\{\begin{array}{ccc} \frac{1}{b - a} & \text{para} & a \leq x \leq b \\ 0 & \text{para} & x < a \text{\; ó \;} x > b \end{array} \right. \]

**EJEMPLO**

Una mujer está dando a luz a un bebé, y la hora exacta del alumbramiento $(X)$ sucederá en cualquier momento entre la hora $0$ (ahora) y la hora $24$ (la misma hora del día siguiente).

a) Para calcular la probabilidad de que la madre de a luz dentro de las primeras cinco horas $(P(X < 5))$ escribiremos:

    ```{r}
    punif(5, min = 0, max = 24, lower.tail = TRUE)
    ```

En distribuciones continuas, $P(X < x)$ equivale a $P(X \leq x)$. En una distribución continua el cálculo de una probabilidad del tipo $P(X = x)$ será siempre nula, es decir, $P(X = x) = 0$.

b) Si queremos calcular la probabilidad de que la madre para en las últimas dos horas (a partir de la hora $22$), estaremos calculando $(P(X > 22))$:

    ```{r}
    punif(22, min = 0, max = 24, lower.tail = FALSE)
    ```

### **DISTRIBUCIÓN EXPONENCIAL**

Esta distribución está relacionada con la distribución de Poisson.

Con esta distribución se modeliza el intervalo de tiempo que transcurre entre dos sucesos. Tiene un único parámetro $\lambda$ y está definida para valores no negativos de la variable aleatoria.

Sus funciones de densidad y de distribución son:

\[ f(x) = \lambda e^{-\lambda x} \]

\[ F(x) = P(X \leq x) = 1 - e^{-\lambda x} \]

**EJEMPLO**

En un hospital, el tiempo que transcurre entre dos partos (medido en horas) sigue una distribución exponencial con un parámetro $\lambda = 4$. Esto significa que la esperanza viene definida como $E(X) = \frac{1}{\lambda} = \frac{1}{4} = 0.25$, de media transcurre un cuarto de hora $(\frac{1}{4} = 0.25)$ entre un parto y otro.

a) La probabiliad de que transcurra una hora o más entre dos partos $(P(X > 1))$:

    ```{r}
    pexp(1, rate = 4, lower.tail = FALSE)
    ```

    Hay aproximadamente un $1.8 \; \%$ de probabilidad de que transcurra una hora o más entre dos partos.

b) La probabilidad de que transcurra como máximo una hora entre dos partos $(P(X \leq 1) = 1 - P(X > 1))$:

    ```{r}
    pexp(1, rate = 4, lower.tail = TRUE)
    ```

    Como vemos, se cumple:
    
    \[ P(X \leq x) + P(X > x) = 1 \]

c) Para obtener la gráfica de la función de densidad, definimos un vector $x$ de $1000$ valores, equiespaciados entre $0$ y $2$ y luego calculamos la función de densidad correspondiente a cada valor, que guardamos en otro vector:
    
    ```{r}
    x <- seq(0, 2, length.out = 1000)
    y <- dexp(x, rate = 4)
    plot(x, y, main = "Distribución exponencial de parámetro 4",
         xlab = "x", ylab = "Densidad", type = "l")
    ```

d) Para la función de distribución tendremos que guardar en el vector los valores de la función de distribución correspondientes a cada uno de los valores de $x$:

    ```{r}
    x <- seq(0, 2, length.out = 1000)
    y <- pexp(x, rate = 4, lower.tail = TRUE)
    plot(x, y, main = "Distribución exponencial de parámetro 4",
         xlab = "x", ylab = "Probabilidad acumulada", type = "l")
    ```

## **DISTRIBUCIÓN NORMAL**

La distribución normal o gaussiana tiene dos parámetros: la media $\mu$ y la desviación típica o estándar $\sigma$. Su función de densidad viene dada por la siguiente expresión:

\[ f(x) = \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2} \left( \frac{x - \mu}{\sigma} \right)^2} \]

**EJEMPLO**

En un hospital, el peso de los bebés al nacer sigue una distribución normal con media $\mu = 3.5$ y desviación típica $\sigma = 0.25$.

a) Queremos visualizar la forma de la función de densidad. Para eso, tenemos que definir un vector $x$ de forma que su mediana sea $3.5$. En este caso, podríamos tomar $1000$ número equidistantes entre $2.5$ y $4.5$ (para asegurarnos de que el $3.5$ queda en la mitad del vector). Luego, calculamos el vector $y$, donde cada componenete será la función de densidad de la coordenada de $x$ correspondiente.

    ```{r}
    x <- seq(2.5, 4.5, length.out = 1000)
    y <- dnorm(x, mean = 3.5, sd = 0.25)
    plot(x, y, main = "Distribución normal de media 3.5 y desviación típica 0.25",
         xlab = "x", ylab = "Densidad", type = "l")
    ```

    Vemos cómo la mayor parte de los niños pesan entre $3$ y $4$ kilos al nacer.

b) Calculamos la probabilidad $P(3 \leq X \leq 4))$

    Al ser una distribución simétrica, vemos que si trazamos una línea vertical en la media aritmética $(3.5)$, en las dos partes de la distribución queda el $50 \; \%$ de la masa probabilística. Esto también se puede ver si nos fijamos en que $\mu = 3.5$ se sitúa en medio de los valores $3$ y $4$; entonces, el área que quedará a la izquierda de $3$ y el área que quedará a la derecha de $4$ serán iguales debido a la simetría de la distribución. Por tanto, si queremos calcular el área que queda entre $3$ y $4$, es decir $P(3 \leq X \leq 4)$, una opción es calcular uno menos las dos colas de los extremos, $P(X \leq 3)$ y $P(X \geq 4)$:
    
    \[ P(3 \leq X \leq 4) = 1 - P(X \leq 3) - P(X \geq 4) \]
    
    Como sabemos que estos dos extremos han de tener el mismo área o valor, es decir, $P(X \leq 3) = P(X \geq 4)$, la fórmula anterior se puede simplificar de la manera siguiente:
    
    \[ P(3 \leq X \leq 4) = 1 - 2P(X \leq 3) \]
    
    Otras formas alternativas de obtener esta probabilidad son:
    
    \[ P(3 \leq X \leq 4) = 1 - 2P(x \geq 4) \]
    
    \[ P(3 \leq X \leq 4) = P(X \leq 4) - P(X \leq 3) \]
    
    Calculamos la probabilidad $P(X \leq 3)$ con *R* siguiendo la primera opción:
    
    ```{r}
    pnorm(3, mean = 3.5, sd = 0.25, lower.tail = TRUE)
    ```
    
    De esta forma, obtenemos que $P(3 \leq X \leq 4) = 1 - 2 \cdot 0.023 = 0.954$, es decir, más del $95 \; \%$ de los bebés nacerán dentro del intervalo de pesos $[3, 4]$.